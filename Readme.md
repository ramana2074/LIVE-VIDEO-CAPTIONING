ğŸ“¸ Live Video Captioning with Audio ğŸ¤
Real-time video captioning using a Transformer model and speaking the captions out loud using TTS!

ğŸš€ Features
ğŸ“· Live Webcam Feed processing

ğŸ§  Transformer-Based Image Captioning with ViT-GPT2

ğŸ—£ï¸ Text-to-Speech (TTS) that speaks out generated captions

ğŸ¨ On-screen Caption Display with wrapped text for readability

âš¡ Efficient Frame Skipping and Resizing to improve performance

ğŸ’» CUDA / CPU device support

ğŸ› ï¸ Requirements
Python 3.7+

PyTorch

OpenCV

pyttsx3

Transformers (ğŸ¤— Hugging Face)

ğŸ¯ How It Works
Opens your webcam ğŸ“·

Captures frames (skipping some to save resources)

Resizes frames for faster caption generation

Generates a caption ğŸ§  using ViT-GPT2

Speaks the caption aloud ğŸ—£ï¸ using pyttsx3

Displays the caption as overlay text ğŸ“ on the live video

Press q to quit gracefully.

Make sure your webcam is connected and accessible.

ğŸ§  Model Used
nlpconnect/vit-gpt2-image-captioning

A Vision Transformer (ViT) encoder + GPT2 decoder model

Pretrained on a large dataset for generic image captioning

ğŸ“ Notes
Frame skipping (frame_skip) can be adjusted to balance speed and caption accuracy.

Resize factor (resize_factor) helps reduce computational load.

Ensure your microphone/speakers are working for TTS output.

CUDA will be used automatically if available ğŸ”¥.

ğŸ¤– Future Ideas
ğŸ¯ Integrate Zero-Shot Object Detection

ğŸŒ Stream captions over a network

ğŸ“± Create a mobile or lightweight version

ğŸ”Š Add multi-language support for TTS
